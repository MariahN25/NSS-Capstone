{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b43433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import columns that have to do with grades by subject\n",
    "grades = pd.read_csv(r\"\\Users\\mnorm\\Documents\\NSS\\NSS-Capstone\\data\\National Longitudinal Study of Adolescent to Adult Health\\ICPSR_21600\\DS0001\\21600-0001-Data.tsv\", sep = '\\t', usecols = ['AID','H1ED11', 'H1ED12', 'H1ED13', 'H1ED14'], low_memory = False)\n",
    "grades = grades.rename(columns = {'AID': 'AID','H1ED11': 'English', 'H1ED12' : 'Math', 'H1ED13' : 'History', 'H1ED14' : 'Science'})\n",
    "grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e566f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = [1,2,3,4,5,6,96,97,98]\n",
    "grade = ['A', 'B', 'C', 'D or lower', 'subject not taken', 'diff grading system', 'refusesd', 'legitimate skip', 'unknown']\n",
    "grade_code = pd.DataFrame(list(zip(key, grade)), columns = ['index', 'grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5599de",
   "metadata": {},
   "outputs": [],
   "source": [
    "English = pd.DataFrame(grades['English'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ac7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "History = pd.DataFrame(grades['History'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e423311",
   "metadata": {},
   "outputs": [],
   "source": [
    "Math = pd.DataFrame(grades['Math'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Science = pd.DataFrame(grades['Science'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f61ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [grade_code, English, History, Math, Science]\n",
    "gradebysub = reduce(lambda left, right: pd.merge(left,right, on = 'index', how = 'inner'), dfs)\n",
    "gradebysub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create total column and row\n",
    "#remove subject not taken and legitimate skip \n",
    "#group AID in grades by grades \n",
    "#EDA peer connection \n",
    "#compare peer connection and grades by EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_students = grades.loc[(grades['English'] == 1) & (grades['History'] == 1) & (grades['Math'] == 1) & (grades['Science'] == 1)]\n",
    "A_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_students = grades.loc[(grades['English'] <= 2) & (grades['Math'] <= 2) & (grades['History'] <= 2) & (grades['Science'] <= 2)]\n",
    "len(AB_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf6b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_below_students = grades.loc[(grades['English'].between(3,4)) & (grades['Math'].between(3,4)) & (grades['History'].between(3,4)) & (grades['Science'].between(3,4))]\n",
    "len(C_below_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda12175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import columns about feeling connected/safe with peers\n",
    "trouble_with = pd.read_csv(r\"\\Users\\mnorm\\Documents\\NSS\\NSS-Capstone\\data\\National Longitudinal Study of Adolescent to Adult Health\\ICPSR_21600\\DS0001\\21600-0001-Data.tsv\", sep = '\\t', usecols = ['AID', 'H1ED15', 'H1ED16', 'H1ED17', 'H1ED18'], low_memory = False)\n",
    "trouble_with.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64fe3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trouble_with = trouble_with.rename(columns = {'AID':'AID','H1ED15':'trouble_get_along_teachers', 'H1ED16':'trouble_paying_attention', 'H1ED17':'trouble_getting_homework_done', 'H1ED18':'trouble_get_along_students'})\n",
    "trouble_with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teachers = pd.DataFrame(trouble_with['trouble_get_along_teachers'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = pd.DataFrame(trouble_with['trouble_paying_attention'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "homework = pd.DataFrame(trouble_with['trouble_getting_homework_done'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.DataFrame(trouble_with['trouble_get_along_students'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb769781",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs2 = [teachers, attention, homework, students]\n",
    "trouble_with_counts = reduce(lambda left, right: pd.merge(left, right, on = 'index', how = 'inner'), dfs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7216ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = [0,1,2,3,4,6,7,8] \n",
    "survey = ['never', 'just a few times', 'about once a week', 'almost everyday', 'everyday', 'refused', 'legitimate skip','don’t know']\n",
    "trouble_with_code = pd.DataFrame(list(zip(code, survey)), columns = ['index', 'answer'])\n",
    "trouble_with_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cbd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trouble = pd.merge(trouble_with_code, trouble_with_counts, how = 'inner', on = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f139dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_safety = pd.read_csv(r\"C:\\Users\\mnorm\\Documents\\NSS\\NSS-Capstone\\data\\National Longitudinal Study of Adolescent to Adult Health\\ICPSR_21600\\DS0001\\21600-0001-Data.tsv\", sep = '\\t', usecols = ['AID', 'H1ED19', 'H1ED20', 'H1ED21', 'H1ED22', 'H1ED23', 'H1ED24'], low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811aa50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_safety = conn_safety.rename(columns = {'AID':'AID','H1ED19':'closeto_peers', 'H1ED20':'partof_school', 'H1ED21':'students_prejudiced', 'H1ED22':'happy_at_school', 'H1ED23':'teachers_fair','H1ED24':'safein_school'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8dc3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "peers = pd.DataFrame(conn_safety['closeto_peers'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab36306",
   "metadata": {},
   "outputs": [],
   "source": [
    "school = pd.DataFrame(conn_safety['partof_school'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b6818",
   "metadata": {},
   "outputs": [],
   "source": [
    "prejudice = pd.DataFrame(conn_safety['students_prejudiced'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy = pd.DataFrame(conn_safety['happy_at_school'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92434a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fair = pd.DataFrame(conn_safety['teachers_fair'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe = pd.DataFrame(conn_safety['safein_school'].value_counts()).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs3 = [peers, school, prejudice, happy, fair, safe]\n",
    "\n",
    "conn_safety_counts = reduce(lambda left, right: pd.merge(left, right, on = 'index', how = 'inner'), dfs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ce6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = [1,2,3,4,5,6,7,8]\n",
    "survey = ['strongly agree', 'agree', 'neither agree nor disagree','disagree', 'strongly disagree' ,'refused', 'legitimate skip', 'don’t know']\n",
    "\n",
    "conn_safety_code = pd.DataFrame(list(zip(code, survey)), columns = ['index', 'survey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_safety_ans = pd.merge(conn_safety_code, conn_safety_counts, how = 'inner', on = 'index')\n",
    "conn_safety_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_safety.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac80c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_peers = conn_safety.loc[(conn_safety['closeto_peers'] <= 2)]\n",
    "close_peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29040e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradeA_peers = pd.merge(A_students, close_peers, how = 'left', on = 'AID')\n",
    "gradeA_peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f81de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradeA_peers.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_below_peers = pd.merge(C_below_students, close_peers, how = 'left', on = 'AID')\n",
    "C_below_peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6656ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_below_peers.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d5583",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_safety_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "notcloseto_peers = conn_safety.loc[conn_safety['closeto_peers'].between(4,5)]\n",
    "notcloseto_peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe695496",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7df5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_students_notclose_peers = pd.merge(A_students, notcloseto_peers, how = 'left', on = 'AID')\n",
    "A_students_notclose_peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_students_notclose_peers.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_below_notclose_peers = pd.merge(C_below_students, notcloseto_peers, how = 'left', on = 'AID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3bd794",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_below_notclose_peers.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee3b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_info = pd.merge(grades, conn_safety, how = 'inner', on = 'AID')\n",
    "student_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b6b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_notclosepeers = student_info.loc[student_info['closeto_peers'].between(4,5)]\n",
    "students_notclosepeers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_notclosepeers['English'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e2fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_notclosepeers['Math'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb0efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_notclosepeers['History'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2882172",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_closetopeers = student_info.loc[student_info['closeto_peers'].between(1,2)]\n",
    "students_closetopeers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a644db",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_closetopeers['English'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a8ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_closetopeers['Math'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_closetopeers['Science'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75301d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_closetopeers['History'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896a765",
   "metadata": {},
   "source": [
    "**Connection to Family**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mom = pd.read_csv(r\"C:\\Users\\mnorm\\Documents\\NSS\\NSS-Capstone\\data\\National Longitudinal Study of Adolescent to Adult Health\\ICPSR_21600\\DS0001\\21600-0001-Data.tsv\", sep = '\\t', usecols = ['AID','H1PF1', 'H1PF2', 'H1PF3', 'H1PF4', 'H1PF5'], low_memory = False)\n",
    "conn_mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81922425",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mom = conn_mom.rename(columns = {'H1PF1': 'loving_mom', 'H1PF2': 'independence_encouraged', 'H1PF3': 'understanding', 'H1PF4': 'communicate_well', 'H1PF5': 'good_relationship'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_safety_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b668ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mom['loving_mom'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e1d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mom['independence_encouraged'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a4e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mom['understanding'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mom['communicate_well'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mom['good_relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8cb6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mom.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b229398",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_mom_info = pd.merge(grades, conn_mom, how = 'inner', on = 'AID')\n",
    "grade_mom_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2082fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_goodmom = grade_mom_info.loc[(grade_mom_info['loving_mom'].between(1,2)) & (grade_mom_info['independence_encouraged'].between(1,2)) & (grade_mom_info['understanding'].between(1,2)) & (grade_mom_info['communicate_well'].between(1,2)) & (grade_mom_info['good_relationship'].between(1,2))]\n",
    "grades_goodmom.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ca2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_goodmom['English'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6532495",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_goodmom['Math'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_goodmom['History'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cabaf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_goodmom['Science'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_mom_info.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
